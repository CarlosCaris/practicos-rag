{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loaders.load import load_documents_from_folder\n",
    "from src.chunking.chunk import chunk_text\n",
    "from src.embedding.embedding import CustomHuggingFaceEmbeddings\n",
    "from src.vector_store_client.vstore import create_vector_store\n",
    "from qdrant_client import QdrantClient\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#Parametros:\n",
    "chunk_size = 500\n",
    "chunk_overlap = 100\n",
    "folder_path = \"../practicos-rag/data\"\n",
    "\n",
    "\n",
    "#Carga de documentos:\n",
    "docs_from_folder = load_documents_from_folder(folder_path)\n",
    "\n",
    "#Chunking\n",
    "splits = chunk_text(docs_from_folder, chunk_size, chunk_overlap)\n",
    "splits[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La dimensi贸n del vector es: 384\n"
     ]
    }
   ],
   "source": [
    "# Crear una instancia de la clase personalizada\n",
    "embedding_model = CustomHuggingFaceEmbeddings(mode=\"sentence\")\n",
    "\n",
    "# Obtener la dimensi贸n del vector\n",
    "dimension = embedding_model.get_dimension()\n",
    "print(f\"La dimensi贸n del vector es: {dimension}\")\n",
    "\n",
    "# Nombre de la colecci贸n\n",
    "collection_name = \"demo_collection2\"\n",
    "update = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar al cliente Qdrant\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "print('Cliente conectado')\n",
    "\n",
    "vector_store = create_vector_store(client, collection_name, embedding_model, splits, dimension, update = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "#!ollama pull llama3.2\n",
    "llm = OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt.messages[0].prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# RAG chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Can you tell me what are the regulations for labeling of cacao and chocolate?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_rags",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
