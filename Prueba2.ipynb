{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chunking.document_splitter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchunking\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SemanticChunker\n",
      "\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'chunking.document_splitter'"
     ]
    }
   ],
   "source": [
    "from src import loaders as loadfile\n",
    "from src import chunking as ch\n",
    "from src import embedding as embed\n",
    "from src import vector_store_client as vstore\n",
    "from qdrant_client import QdrantClient\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#Parametros:\n",
    "chunk_size = 500\n",
    "chunk_overlap = 100\n",
    "folder_path = \"../practicos-rag/data\"\n",
    "\n",
    "\n",
    "#Carga de documentos:\n",
    "docs_from_folder = loadfile.load_documents_from_folder(folder_path)\n",
    "\n",
    "#Chunking\n",
    "splits = ch.chunk_text(docs_from_folder, chunk_size, chunk_overlap)\n",
    "splits[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una instancia de la clase personalizada\n",
    "embedding_model = embed.CustomHuggingFaceEmbeddings(mode=\"sentence\")\n",
    "\n",
    "# Obtener la dimensión del vector\n",
    "dimension = embedding_model.get_dimension()\n",
    "print(f\"La dimensión del vector es: {dimension}\")\n",
    "\n",
    "# Nombre de la colección\n",
    "collection_name = \"demo_collection2\"\n",
    "update = True\n",
    "\n",
    "# Conectar al cliente Qdrant\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "print('Cliente conectado')\n",
    "\n",
    "vector_store = vstore.create_vector_store(client, collection_name, embedding_model, splits, dimension, update = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "#!ollama pull llama3.2\n",
    "llm = OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt.messages[0].prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# RAG chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Can you tell me what are the regulations for labeling of cacao and chocolate?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
