{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184c1daa",
   "metadata": {},
   "source": [
    "In this tutorial, we show you how to build a simple in-memory vector store that can store documents along with metadata. It will also expose a query interface that can support a variety of queries:\n",
    "\n",
    "- semantic search (with embedding similarity)\n",
    "- metadata filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c05da61",
   "metadata": {},
   "source": [
    "# Donwload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c0563f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\n",
      "--2025-08-26 10:21:23--  https://arxiv.org/pdf/2307.09288.pdf\n",
      "Resolviendo arxiv.org (arxiv.org)... 151.101.195.42, 151.101.67.42, 151.101.3.42, ...\n",
      "Conectando con arxiv.org (arxiv.org)[151.101.195.42]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 301 Moved Permanently\n",
      "Localización: /pdf/2307.09288 [siguiendo]\n",
      "--2025-08-26 10:21:24--  https://arxiv.org/pdf/2307.09288\n",
      "Reutilizando la conexión con arxiv.org:443.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 13661300 (13M) [application/pdf]\n",
      "Grabando a: «data/llama2.pdf»\n",
      "\n",
      "data/llama2.pdf     100%[===================>]  13.03M  3.61MB/s    en 3.6s    \n",
      "\n",
      "2025-08-26 10:21:27 (3.61 MB/s) - «data/llama2.pdf» guardado [13661300/13661300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc95e08",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33b11a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import  Any, cast\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.bridge.pydantic import Field\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import TextNode, BaseNode\n",
    "from llama_index.core.vector_stores import MetadataFilters, VectorStoreQuery, VectorStoreQueryResult\n",
    "from llama_index.core.vector_stores.types import BasePydanticVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb1363",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512023d7",
   "metadata": {},
   "source": [
    "We load in some documents, and parse them into `Node` objects - chunks that are ready to be inserted into a vector store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8ba22a",
   "metadata": {},
   "source": [
    "### Load in Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e74e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFReader()\n",
    "documents = loader.load(file_path=\"./data/llama2.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a971450d",
   "metadata": {},
   "source": [
    "### Parse into Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb9e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SentenceSplitter(chunk_size=256)\n",
    "nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a5799e",
   "metadata": {},
   "source": [
    "### Generate Embeddings for each Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd4e55d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 11:34:21,036 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en\n",
      "2025-08-26 11:34:23,996 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    }
   ],
   "source": [
    "embed_model  = HuggingFaceEmbedding(model_name = \"BAAI/bge-small-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a58f3c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    node_embedding = embed_model.get_text_embedding(\n",
    "        node.get_content(metadata_mode=\"all\")\n",
    "    )\n",
    "    node.embedding = node_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188eb83",
   "metadata": {},
   "source": [
    "# Build a Simple In-Memory Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b222f5",
   "metadata": {},
   "source": [
    "Now we'll build our in-memory vector store. We'll store Nodes within a simple Python dictionary. We'll start off implementing embedding search, and add metadata filters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331c1674",
   "metadata": {},
   "source": [
    "## 1. Defining the Interface\n",
    "We'll first define the interface for building a vector store. It contains the following items:\n",
    "    - get\n",
    "    - add\n",
    "    - delete\n",
    "    - query\n",
    "    - persist (which we will not implement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb75c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseVectorStore(BasePydanticVectorStore):\n",
    "    \"\"\"Simple custom Vector Store.\n",
    "\n",
    "    Stores documents in a simple in-memory dict.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    stores_text: bool = True\n",
    "\n",
    "    def client(self) -> Any:\n",
    "        \"\"\"Get client.\"\"\"\n",
    "        return None\n",
    "\n",
    "    def get(self, text_id: str) -> list[float]:\n",
    "        \"\"\"Get embedding.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def add(\n",
    "        self,\n",
    "        nodes: list[BaseNode],\n",
    "    ) -> list[str]:\n",
    "        \"\"\"Add nodes to index.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def delete(self, ref_doc_id: str, **delete_kwargs: Any) -> None:\n",
    "        \"\"\"\n",
    "        Delete nodes using with ref_doc_id.\n",
    "\n",
    "        Args:\n",
    "            ref_doc_id (str): The doc_id of the document to delete.\n",
    "\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def query(\n",
    "        self,\n",
    "        query: VectorStoreQuery,\n",
    "        **kwargs: Any,\n",
    "    ) -> VectorStoreQueryResult:\n",
    "        \"\"\"Get nodes for response.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def persist(self, persist_path, fs=None) -> None:\n",
    "        \"\"\"Persist the SimpleVectorStore to a directory.\n",
    "\n",
    "        NOTE: we are not implementing this for now.\n",
    "\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2bc310",
   "metadata": {},
   "source": [
    "\n",
    "At a high-level, we subclass our base `VectorStore` abstraction. There's no inherent reason to do this if you're just building a vector store from scratch. We do it because it makes it easy to plug into our downstream abstractions later.\n",
    "\n",
    "Let's look at some of the classes defined here.\n",
    "\n",
    "`BaseNode` is simply the parent class of our core Node modules. Each Node represents a text chunk + associated metadata.\n",
    "We also use some lower-level constructs, for instance our `VectorStoreQuery` and `VectorStoreQueryResult`. These are just lightweight dataclass containers to represent queries and results. We look at the dataclass fields below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c34b997",
   "metadata": {},
   "source": [
    "## 2. Defining add, get, and delete\n",
    "We add some basic capabilities to add, get, and delete from a vector store.\n",
    "\n",
    "The implementation is very simple (everything is just stored in a python dictionary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1069c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore2(BaseVectorStore):\n",
    "    \"\"\"VectorStore2 (add/get/delete implemented).\"\"\"\n",
    "\n",
    "    stores_text: bool = True\n",
    "    node_dict: dict[str, BaseNode] = Field(default_factory=dict)\n",
    "\n",
    "    def get(self, text_id: str) -> list[float]:\n",
    "        \"\"\"Get embedding.\"\"\"\n",
    "        return self.node_dict[text_id]\n",
    "\n",
    "    def add(\n",
    "        self,\n",
    "        nodes: list[BaseNode],\n",
    "    ) -> list[str]:\n",
    "        \"\"\"Add nodes to index.\"\"\"\n",
    "        for node in nodes:\n",
    "            self.node_dict[node.node_id] = node\n",
    "\n",
    "    def delete(self, node_id: str, **delete_kwargs: Any) -> None:\n",
    "        \"\"\"\n",
    "        Delete nodes using with node_id.\n",
    "\n",
    "        Args:\n",
    "            node_id: str\n",
    "\n",
    "        \"\"\"\n",
    "        del self.node_dict[node_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f01a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_node = TextNode(id_=\"id1\", text=\"hello world\")\n",
    "test_node2 = TextNode(id_=\"id2\", text=\"foo bar\")\n",
    "test_nodes = [test_node, test_node2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ac5ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = VectorStore2()\n",
    "\n",
    "vector_store.add(test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84cc9bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: id1\n",
      "Text: hello world\n"
     ]
    }
   ],
   "source": [
    "node = vector_store.get(\"id1\")\n",
    "print(str(node))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9ad151",
   "metadata": {},
   "source": [
    "## 3.a Defining query (semantic search)\n",
    "We implement a basic version of top-k semantic search. This simply iterates through all document embeddings, and compute cosine-similarity with the query embedding. The top-k documents by cosine similarity are returned.\n",
    "\n",
    "Cosine similarity: $\\dfrac{\\vec{d}\\vec{q}}{|\\vec{d}||\\vec{q}|}$ for every document, query embedding pair $\\vec{d}$, $\\vec{p}$.\n",
    "\n",
    "NOTE: The top-k value is contained in the VectorStoreQuery container.\n",
    "\n",
    "NOTE: Similar to the above, we define another subclass just so we don't have to reimplement the above functions (not because this is actually good code practice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d37c2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_embeddings(\n",
    "    query_embedding: list[float],\n",
    "    doc_embeddings: list[list[float]],\n",
    "    doc_ids: list[str],\n",
    "    similarity_top_k: int = 5,\n",
    ") -> tuple[list[float], list]:\n",
    "    \"\"\"Get top nodes by similarity to the query.\"\"\"\n",
    "    # dimensions: D\n",
    "    q_embed_np = np.array(query_embedding)\n",
    "    # dimensions: N x D\n",
    "    d_embed_np = np.array(doc_embeddings)\n",
    "    # dimensions: N\n",
    "    d_product_arr = np.dot(d_embed_np, q_embed_np)\n",
    "    # dimensions: N\n",
    "    norm_arr = np.linalg.norm(q_embed_np) * np.linalg.norm(\n",
    "        d_embed_np, axis=1, keepdims=False\n",
    "    )\n",
    "    # dimensions: N\n",
    "    cos_sim_arr = d_product_arr / norm_arr\n",
    "\n",
    "    # now we have the N cosine similarities for each document\n",
    "    # sort by top k cosine similarity, and return ids\n",
    "    tups = [(cos_sim_arr[i], doc_ids[i]) for i in range(len(doc_ids))]\n",
    "    sorted_tups = sorted(tups, key=lambda t: t[0], reverse=True)\n",
    "\n",
    "    sorted_tups = sorted_tups[:similarity_top_k]\n",
    "\n",
    "    result_similarities = [s for s, _ in sorted_tups]\n",
    "    result_ids = [n for _, n in sorted_tups]\n",
    "    return result_similarities, result_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32961d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore3A(VectorStore2):\n",
    "    \"\"\"Implements semantic/dense search.\"\"\"\n",
    "\n",
    "    def query(\n",
    "        self,\n",
    "        query: VectorStoreQuery,\n",
    "        **kwargs: Any,\n",
    "    ) -> VectorStoreQueryResult:\n",
    "        \"\"\"Get nodes for response.\"\"\"\n",
    "\n",
    "        query_embedding = cast(list[float], query.query_embedding)\n",
    "        doc_embeddings = [n.embedding for n in self.node_dict.values()]\n",
    "        doc_ids = [n.node_id for n in self.node_dict.values()]\n",
    "\n",
    "        similarities, node_ids = get_top_k_embeddings(\n",
    "            query_embedding,\n",
    "            doc_embeddings,\n",
    "            doc_ids,\n",
    "            similarity_top_k=query.similarity_top_k,\n",
    "        )\n",
    "        result_nodes = [self.node_dict[node_id] for node_id in node_ids]\n",
    "\n",
    "        return VectorStoreQueryResult(\n",
    "            nodes=result_nodes, similarities=similarities, ids=node_ids\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d84b25",
   "metadata": {},
   "source": [
    "## 3.b. Supporting Metadata Filtering\n",
    "The next extension is adding metadata filter support. This means that we will first filter the candidate set with documents that pass the metadata filters, and then perform semantic querying.\n",
    "\n",
    "For simplicity we use metadata filters for exact matching with an AND condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1aba966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nodes(nodes: list[BaseNode], filters: MetadataFilters):\n",
    "    filtered_nodes = []\n",
    "    for node in nodes:\n",
    "        matches = True\n",
    "        for f in filters.filters:\n",
    "            if f.key not in node.metadata:\n",
    "                matches = False\n",
    "                continue\n",
    "            if f.value != node.metadata[f.key]:\n",
    "                matches = False\n",
    "                continue\n",
    "        if matches:\n",
    "            filtered_nodes.append(node)\n",
    "    return filtered_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1a8b8b",
   "metadata": {},
   "source": [
    "We add filter_nodes as a first-pass over the nodes before running semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e31da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_search(query: VectorStoreQuery, nodes: list[BaseNode]):\n",
    "    \"\"\"Dense search.\"\"\"\n",
    "    query_embedding = cast(list[float], query.query_embedding)\n",
    "    doc_embeddings = [n.embedding for n in nodes]\n",
    "    doc_ids = [n.node_id for n in nodes]\n",
    "    return get_top_k_embeddings(\n",
    "        query_embedding,\n",
    "        doc_embeddings,\n",
    "        doc_ids,\n",
    "        similarity_top_k=query.similarity_top_k,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34392d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore3B(VectorStore2):\n",
    "    \"\"\"Implements Metadata Filtering.\"\"\"\n",
    "\n",
    "    def query(\n",
    "        self,\n",
    "        query: VectorStoreQuery,\n",
    "        **kwargs: Any,\n",
    "    ) -> VectorStoreQueryResult:\n",
    "        \"\"\"Get nodes for response.\"\"\"\n",
    "        # 1. First filter by metadata\n",
    "        nodes = self.node_dict.values()\n",
    "        if query.filters is not None:\n",
    "            nodes = filter_nodes(nodes, query.filters)\n",
    "        if len(nodes) == 0:\n",
    "            result_nodes = []\n",
    "            similarities = []\n",
    "            node_ids = []\n",
    "        else:\n",
    "            # 2. Then perform semantic search\n",
    "            similarities, node_ids = dense_search(query, nodes)\n",
    "            result_nodes = [self.node_dict[node_id] for node_id in node_ids]\n",
    "        return VectorStoreQueryResult(\n",
    "            nodes=result_nodes, similarities=similarities, ids=node_ids\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7d978e",
   "metadata": {},
   "source": [
    "## 4. Load Data into our Vector Store\n",
    "Let's load our text chunks into the vector store, and run it on different types of queries: dense search, w/ metadata filters, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d9d0a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = VectorStore3B()\n",
    "# load data into the vector stores\n",
    "vector_store.add(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2204f0ce",
   "metadata": {},
   "source": [
    "Define an example question and embed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19826e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.057459719479084015, 0.0006168371182866395, 0.0073997811414301395, -0.026107775047421455, 0.010598297230899334, 0.0079874899238348, 0.06677503138780594, 0.039609961211681366, 0.002579552587121725, -0.0042901113629341125, -0.05172336474061012, -0.03663443773984909, 0.016417549923062325, 0.020253019407391548, 0.005108681973069906, 0.0037742929998785257, 0.03296405449509621, 0.0320092998445034, -0.008439943194389343, 0.01931261643767357, -0.004506618250161409, 0.031248915940523148, -0.024012690410017967, -0.020971687510609627, 0.004960776772350073, -0.0026956091169267893, 0.017490452155470848, 0.0022530765272676945, -0.01721314713358879, -0.19273661077022552, -0.04692849516868591, -0.03517277166247368, -0.02127939835190773, -0.007309731561690569, -0.020944062620401382, -0.008686739951372147, -0.028816986829042435, 0.03126359358429909, -0.004988355562090874, -0.003774945391342044, 0.04736080393195152, 0.017691636458039284, -0.008748933672904968, -0.009141991846263409, -0.01443557720631361, -0.03179141506552696, 0.014844904653728008, -0.014371468685567379, 0.011276059783995152, -0.033967409282922745, 0.02256648801267147, -0.06226889789104462, 0.011123048141598701, 0.040709879249334335, 0.00619336636736989, -0.019459806382656097, 0.047524791210889816, -0.017023257911205292, 0.03172086179256439, 0.03288192301988602, 0.035637445747852325, 0.0049617658369243145, -0.22939303517341614, 0.05001296103000641, 0.037386417388916016, 0.01707783155143261, -0.06055411696434021, -0.00746917212381959, 0.04383733868598938, 0.052198026329278946, -0.04051165282726288, 0.01073480024933815, -0.0026650861836969852, 0.0346045158803463, 0.011445970274508, -0.0006426980835385621, -0.0035224093589931726, -0.022404924035072327, -0.03026100993156433, 0.019131071865558624, 0.002631835173815489, 0.0030924491584300995, -0.00868062674999237, -0.004652394913136959, -0.0353320837020874, -0.022634457796812057, 0.008173736743628979, -0.01849711500108242, 0.058947909623384476, -0.02757573314011097, -0.003948612604290247, -0.014733324758708477, 0.015612205490469933, 0.004900627303868532, -0.016957493498921394, -0.029817232862114906, 0.022692887112498283, 0.0019688305910676718, -0.059244558215141296, 0.5568937659263611, 0.014852061867713928, 0.007682453840970993, -0.0003968331147916615, -0.04328392818570137, -0.0009033245733007789, -0.00047666922910138965, -0.0028102765791118145, -0.03579293563961983, 0.03440879285335541, -0.01750089041888714, 0.06579440087080002, 0.021408239379525185, 0.035790976136922836, -0.05869942158460617, 0.02212994173169136, 0.01106199249625206, 0.02487356588244438, 0.032369110733270645, 0.04357122629880905, 0.011543815955519676, 0.00517289899289608, -5.469833195093088e-05, 0.02321545220911503, -0.022813931107521057, 0.010534719564020634, -0.05636307969689369, 0.015465622767806053, 0.0316527858376503, 0.015002820640802383, 0.04551690071821213, 0.03507150337100029, -0.04583929851651192, -0.011443535797297955, 0.005099904723465443, 0.04253677651286125, 0.02628357894718647, 0.0019310952629894018, 0.04406760632991791, 0.03663928806781769, 0.016830619424581528, -0.00638993876054883, -0.027171719819307327, 0.00692938594147563, -0.08807391673326492, -0.010195166803896427, 0.07470181584358215, -0.046537697315216064, -0.03825310617685318, 0.0042552403174340725, 0.027977585792541504, -0.026997581124305725, -0.024262428283691406, -0.002787227975204587, 0.009473691694438457, 0.048838526010513306, 0.01847347617149353, 0.06538654118776321, -0.00444924458861351, 0.010156805627048016, 0.0030984242912381887, 0.027741800993680954, -0.05556010827422142, -0.042029570788145065, 0.10762946307659149, 0.02032143995165825, -0.0843367874622345, -0.03488151356577873, 0.027963954955339432, 0.005946243181824684, -0.07063156366348267, 0.013553655706346035, 0.043927259743213654, 0.01748013123869896, 0.0070774066261947155, 0.047939445823431015, 0.03988019376993179, -0.03746938332915306, -0.005156693980097771, -0.0017877077916637063, 0.012780866585671902, 0.029970860108733177, -0.055308833718299866, -0.027438407763838768, 0.027380231767892838, 0.006574062630534172, -0.03124304488301277, -0.016395512968301773, -0.025616895407438278, 0.011955870315432549, 0.03154739737510681, -0.07553613930940628, -0.02106277458369732, -0.051470447331666946, 0.012254809029400349, -0.018709827214479446, 0.01976916939020157, -0.022660456597805023, -0.04181560501456261, -0.033198826014995575, -0.018095646053552628, -0.018071476370096207, 0.030971156433224678, -0.024407029151916504, 0.020371735095977783, -0.016694767400622368, 0.05950343608856201, 0.006635477300733328, -0.052398961037397385, 0.02186471037566662, 0.046696729958057404, -0.04731142893433571, 0.018467586487531662, 0.030451595783233643, -0.029651423916220665, 0.02749127708375454, -0.011497674509882927, 0.030490949749946594, 0.08592380583286285, -0.014730948023498058, 0.0038556659128516912, 0.039726462215185165, -0.007360904943197966, -0.05267252400517464, -0.26506248116493225, -0.004205149598419666, -0.04992308467626572, -0.04608022794127464, 0.04779163748025894, 0.005346058402210474, 0.004466706421226263, -0.05271117389202118, -0.034016869962215424, 0.010383158922195435, 0.10346558690071106, -0.011906985193490982, -0.03485245630145073, -0.004784577060490847, 0.003324127523228526, -0.016659827902913094, -0.041042160242795944, -0.02461540512740612, -0.029713815078139305, 0.025853723287582397, 0.021279064938426018, 0.04438544064760208, -0.02251785434782505, -0.04514078423380852, 0.0062731592915952206, -0.04900107532739639, 0.1533016562461853, -0.06291752308607101, 0.03405475988984108, -0.0871037021279335, 0.032095275819301605, 0.002256514271721244, 0.008197550661861897, -0.09039771556854248, 0.07180222868919373, -0.020147979259490967, -0.02002088725566864, 0.03983258828520775, -0.02496299147605896, -0.02909989282488823, -0.014416323974728584, 0.0013768947683274746, -0.05808037891983986, -0.03395567461848259, -0.056557461619377136, -0.05444038286805153, -0.027331402525305748, 0.01692953146994114, -0.01735803298652172, 0.00673171691596508, 0.005833002272993326, 0.006197081878781319, 0.008196963928639889, 0.05873089283704758, 0.0012966231442987919, -0.05289773643016815, -0.05567115172743797, 0.05931124836206436, -0.08881249278783798, -0.01713269017636776, -0.007047206163406372, -0.003012052970007062, 0.040131088346242905, -0.033321231603622437, 0.0351734384894371, 0.0065891011618077755, 0.0017237437423318624, -0.023320108652114868, 0.006192932836711407, -0.032996539026498795, -0.034810807555913925, 0.08181260526180267, 0.019100191071629524, -0.003092988394200802, 0.0322994664311409, 0.00632655993103981, -0.016880642622709274, -0.013847153633832932, -0.022015385329723358, -0.015142272226512432, 0.019616030156612396, -0.005917576141655445, 0.03346383571624756, 0.003856141585856676, -0.023139342665672302, -0.008749726228415966, 0.006105180364102125, -0.02531045861542225, 0.011858753859996796, 0.01802515611052513, -0.014152358286082745, -0.011295917443931103, -0.002338182646781206, -0.028960049152374268, -0.0025235407520085573, 0.022211436182260513, -0.27014416456222534, 0.020244428887963295, -0.037267234176397324, 0.023057496175169945, 0.006620149128139019, -0.005738267209380865, 0.052929896861314774, -0.02519230730831623, 0.03366168960928917, 0.01738899201154709, 0.003910557366907597, 0.04383259266614914, 0.01676347851753235, 0.031340815126895905, 0.0034782439470291138, 0.023279255256056786, 0.03731158375740051, -0.014880497939884663, -0.021190015599131584, 0.01038010697811842, 0.0011236920254305005, 0.035115551203489304, 0.17353886365890503, 0.009348683059215546, 0.010357139632105827, 0.028976982459425926, -0.00682424521073699, 0.01770714484155178, 0.014328141696751118, 0.006178691051900387, 0.045608680695295334, -0.012570986524224281, 0.0733330100774765, -0.032031212002038956, 0.029335951432585716, 0.027158698067069054, -0.0029565133154392242, 0.05219266936182976, 0.03671599552035332, 0.002569065894931555, -0.002636086428537965, -0.023730387911200523, 0.05152149498462677, -0.027746913954615593, 0.05118770897388458, -0.029671939089894295, -0.042937539517879486, -0.05463379621505737, -0.004475342575460672, 0.014210396446287632, -0.03161512687802315, -0.008067306131124496, -0.0030675576999783516, -0.023505546152591705, 0.04967789351940155, 0.04547758772969246, 0.008374753408133984, 0.014891323633491993, -0.00041665678145363927, -0.013337054289877415, 0.021680057048797607, -0.00770636647939682, -0.03791985660791397, 0.04514266178011894, -0.006717783398926258]\n"
     ]
    }
   ],
   "source": [
    "query_str = \"Can you tell me about the key concepts for safety finetuning\"\n",
    "query_embedding = embed_model.get_query_embedding(query_str)\n",
    "print(query_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564c584d",
   "metadata": {},
   "source": [
    "### Query the vector store with dense search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4a40863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------\n",
      "[Node ID 5c848fc0-d442-4e5a-8f67-f5105b4009c3] Similarity: 0.871129510942508\n",
      "\n",
      "total_pages: 77\n",
      "file_path: ./data/llama2.pdf\n",
      "source: 23\n",
      "\n",
      "Benchmarks give a summary view of model capabilities and behaviors that allow us to understand general\n",
      "patterns in the model, but they do not provide a fully comprehensive view of the impact the model may have\n",
      "on people or real-world outcomes; that would require study of end-to-end product deployments. Further\n",
      "testing and mitigation should be done to understand bias and other social issues for the specific context\n",
      "in which a system may be deployed. For this, it may be necessary to test beyond the groups available in\n",
      "the BOLD dataset (race, religion, and gender). As LLMs are integrated and deployed, we look forward to\n",
      "continuing research that will amplify their potential for positive impact on these important social issues.\n",
      "4.2\n",
      "Safety Fine-Tuning\n",
      "In this section, we describe our approach to safety fine-tuning, including safety categories, annotation\n",
      "guidelines, and the techniques we use to mitigate safety risks. We employ a process similar to the general\n",
      "fine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\n",
      "----------------\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "[Node ID f57e19f9-b1aa-41cb-b4d4-703357a57539] Similarity: 0.8678354021927739\n",
      "\n",
      "total_pages: 77\n",
      "file_path: ./data/llama2.pdf\n",
      "source: 23\n",
      "\n",
      "Further\n",
      "testing and mitigation should be done to understand bias and other social issues for the specific context\n",
      "in which a system may be deployed. For this, it may be necessary to test beyond the groups available in\n",
      "the BOLD dataset (race, religion, and gender). As LLMs are integrated and deployed, we look forward to\n",
      "continuing research that will amplify their potential for positive impact on these important social issues.\n",
      "4.2\n",
      "Safety Fine-Tuning\n",
      "In this section, we describe our approach to safety fine-tuning, including safety categories, annotation\n",
      "guidelines, and the techniques we use to mitigate safety risks. We employ a process similar to the general\n",
      "fine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\n",
      "Specifically, we use the following techniques in safety fine-tuning:\n",
      "1. Supervised Safety Fine-Tuning: We initialize by gathering adversarial prompts and safe demonstra-\n",
      "tions that are then included in the general supervised fine-tuning process (Section 3.1).\n",
      "----------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_obj = VectorStoreQuery(\n",
    "    query_embedding=query_embedding, similarity_top_k=2\n",
    ")\n",
    "\n",
    "query_result = vector_store.query(query_obj)\n",
    "for similarity, node in zip(query_result.similarities, query_result.nodes):\n",
    "    print(\n",
    "        \"\\n----------------\\n\"\n",
    "        f\"[Node ID {node.node_id}] Similarity: {similarity}\\n\\n\"\n",
    "        f\"{node.get_content(metadata_mode='all')}\"\n",
    "        \"\\n----------------\\n\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85726c1d",
   "metadata": {},
   "source": [
    "### Query the vector store with dense search + Metadata Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f39d58bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------\n",
      "[Node ID 42365dea-7b3c-4c25-91a2-be30c4d8dc00] Similarity: 0.8589715603640367\n",
      "\n",
      "total_pages: 77\n",
      "file_path: ./data/llama2.pdf\n",
      "source: 24\n",
      "\n",
      "We then define best practices for safe and helpful model responses: the model should first address immediate\n",
      "safety concerns if applicable, then address the prompt by explaining the potential risks to the user, and finally\n",
      "provide additional information if possible. We also ask the annotators to avoid negative user experience\n",
      "categories (see Appendix A.5.2). The guidelines are meant to be a general guide for the model and are\n",
      "iteratively refined and revised to include newly identified risks.\n",
      "4.2.2\n",
      "Safety Supervised Fine-Tuning\n",
      "In accordance with the established guidelines from Section 4.2.1, we gather prompts and demonstrations\n",
      "of safe model responses from trained annotators, and use the data for supervised fine-tuning in the same\n",
      "manner as described in Section 3.1. An example can be found in Table 5.\n",
      "The annotators are instructed to initially come up with prompts that they think could potentially induce\n",
      "the model to exhibit unsafe behavior, i.e., perform red teaming, as defined by the guidelines. Subsequently,\n",
      "annotators are tasked with crafting a safe and helpful response that the model should produce.\n",
      "----------------\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "[Node ID 57cf7973-77a2-4609-b19a-c8093c8681dd] Similarity: 0.849598207436732\n",
      "\n",
      "total_pages: 77\n",
      "file_path: ./data/llama2.pdf\n",
      "source: 24\n",
      "\n",
      "advice). The attack vectors explored consist of psychological manipulation (e.g., authority manipulation),\n",
      "logic manipulation (e.g., false premises), syntactic manipulation (e.g., misspelling), semantic manipulation\n",
      "(e.g., metaphor), perspective manipulation (e.g., role playing), non-English languages, and others.\n",
      "We then define best practices for safe and helpful model responses: the model should first address immediate\n",
      "safety concerns if applicable, then address the prompt by explaining the potential risks to the user, and finally\n",
      "provide additional information if possible. We also ask the annotators to avoid negative user experience\n",
      "categories (see Appendix A.5.2). The guidelines are meant to be a general guide for the model and are\n",
      "iteratively refined and revised to include newly identified risks.\n",
      "4.2.2\n",
      "Safety Supervised Fine-Tuning\n",
      "In accordance with the established guidelines from Section 4.2.1, we gather prompts and demonstrations\n",
      "of safe model responses from trained annotators, and use the data for supervised fine-tuning in the same\n",
      "manner as described in Section 3.1.\n",
      "----------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gp/286d79g11513f730wt0d61kc0000gq/T/ipykernel_61069/4088133968.py:6: DeprecationWarning: Call to deprecated class method from_dict. (`from_dict()` is deprecated. Please use `MetadataFilters(filters=.., condition='and')` directly instead.)\n",
      "  filters = MetadataFilters.from_dict({\"source\": \"24\"})\n"
     ]
    }
   ],
   "source": [
    "# filters = MetadataFilters(\n",
    "#     filters=[\n",
    "#         ExactMatchFilter(key=\"page\", value=3)\n",
    "#     ]\n",
    "# )\n",
    "filters = MetadataFilters.from_dict({\"source\": \"24\"})\n",
    "\n",
    "query_obj = VectorStoreQuery(\n",
    "    query_embedding=query_embedding, similarity_top_k=2, filters=filters\n",
    ")\n",
    "\n",
    "query_result = vector_store.query(query_obj)\n",
    "for similarity, node in zip(query_result.similarities, query_result.nodes):\n",
    "    print(\n",
    "        \"\\n----------------\\n\"\n",
    "        f\"[Node ID {node.node_id}] Similarity: {similarity}\\n\\n\"\n",
    "        f\"{node.get_content(metadata_mode='all')}\"\n",
    "        \"\\n----------------\\n\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d18d6",
   "metadata": {},
   "source": [
    "## Build a RAG System with the Vector Store\n",
    "Now that we've built the RAG system, it's time to plug it into our downstream system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f633cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_vector_store(vector_store, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee8530c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceLLM(\n",
    "    model_name=\"google/gemma-3-270m\", \n",
    "    tokenizer_name=\"google/gemma-3-270m\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20ee8fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Life is the eternal quest for meaning and purpose.\n",
      "It may seem a small world for most people. For that person to be happy, or to have something else important to them is meaningless. But, if they really care about themselves and their future, then they have something important for them. So why do they keep waiting for something more valuable? That was the question for my grandfather, who always felt like he was waiting. Why did he sit all these long years? His answers are different depending on who you ask. Some people have a spiritual meaning to life, and are happy because they are spiritual. Others are happy because they live a full, meaningful life. But, for others, it is the end of the world. What has caused their problem? Why are they sitting here all day?\n",
      "At age 67, I am still sitting here at my parents’ house, waiting for the answer. While my mother and I have gone through the same experiences as my grandfather, I do not know what has caused my mom to get to the point she has. She has spent most of the past five years with her three young daughters, hoping the baby will be a good mother and a good wife, and trying to do everything to get there. I don\n"
     ]
    }
   ],
   "source": [
    "response = llm.complete(\"What is the meaning of life?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50aa97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb560d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"Can you tell me about the key concepts for safety finetuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddb54268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) The general framework for fine-tuning.\n",
      "2) The importance of labeling and fine-tuning.\n",
      "3) The safety category of the model for fine-tuning.\n",
      "4) The methods for fine-tuning the model in the particular environment.\n",
      "5) The method for fine-tuning the model in a specific environment.\n",
      "5.1. Supervised Safety Fine-Tuning\n",
      "Our approach to the fine-tuning process is similar to the previous section: we employ a series of tasks to collect\n",
      "as many adversarial prompts as possible while ensuring that the prompts are both clean and unconstrained. We\n",
      "implement one prompt in each model: the default prompt for a general fine-tuning task. We then collect\n",
      "these prompts and fine-tune the model using these prompts.\n",
      "---------------------\n",
      "Our process for fine-tuning an LLM and a large unlabeled dataset follows the same pattern as the previous\n",
      "section: we collect adversarial prompt questions from our LLM and fine-tune it using the same prompts.\n",
      "This process is similar to the previous section, except that we can choose a dataset based on what we find\n",
      "interesting. We do not fine-tune all datasets; that is, we fine-tune only the prompts that are relevant to\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(query_str)\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724dee61",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "That's it! We've built a simple in-memory vector store that supports very simple inserts, gets, deletes, and supports dense search and metadata filtering. This can then be plugged into the rest of LlamaIndex abstractions.\n",
    "\n",
    "It doesn't support sparse search yet and is obviously not meant to be used in any sort of actual app. But this should expose some of what's going on under the hood!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
